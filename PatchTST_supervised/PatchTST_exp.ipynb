{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80297306-cc2e-40fb-a534-e5bf05b8b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_provider.data_factory import data_provider\n",
    "from exp.exp_basic import Exp_Basic\n",
    "from models import Informer, Autoformer, Transformer, DLinear, Linear, NLinear, PatchTST\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate, visual, test_params_flop\n",
    "from utils.metrics import metric\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler \n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Exp_Main(Exp_Basic):\n",
    "    def __init__(self, args):\n",
    "        super(Exp_Main, self).__init__(args)\n",
    "\n",
    "    def _build_model(self):\n",
    "        model_dict = {\n",
    "            'Autoformer': Autoformer,\n",
    "            'Transformer': Transformer,\n",
    "            'Informer': Informer,\n",
    "            'DLinear': DLinear,\n",
    "            'NLinear': NLinear,\n",
    "            'Linear': Linear,\n",
    "            'PatchTST': PatchTST,\n",
    "        }\n",
    "        model = model_dict[self.args.model].Model(self.args).float()\n",
    "\n",
    "        if self.args.use_multi_gpu and self.args.use_gpu:\n",
    "            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n",
    "        return model\n",
    "\n",
    "    def _get_data(self, flag):\n",
    "        data_set, data_loader = data_provider(self.args, flag)\n",
    "        return data_set, data_loader\n",
    "\n",
    "    def _select_optimizer(self):\n",
    "        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
    "        return model_optim\n",
    "\n",
    "    def _select_criterion(self):\n",
    "        criterion = nn.MSELoss()\n",
    "        return criterion\n",
    "\n",
    "    def vali(self, vali_data, vali_loader, criterion):\n",
    "        total_loss = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float()\n",
    "\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                        else:\n",
    "                            if self.args.output_attention:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                            else:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                        outputs = self.model(batch_x)\n",
    "                    else:\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "\n",
    "                pred = outputs.detach().cpu()\n",
    "                true = batch_y.detach().cpu()\n",
    "\n",
    "                loss = criterion(pred, true)\n",
    "\n",
    "                total_loss.append(loss)\n",
    "        total_loss = np.average(total_loss)\n",
    "        self.model.train()\n",
    "        return total_loss\n",
    "\n",
    "    def train(self, setting):\n",
    "        train_data, train_loader = self._get_data(flag='train')\n",
    "        vali_data, vali_loader = self._get_data(flag='val')\n",
    "        test_data, test_loader = self._get_data(flag='test')\n",
    "\n",
    "        path = os.path.join(self.args.checkpoints, setting)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        time_now = time.time()\n",
    "\n",
    "        train_steps = len(train_loader)\n",
    "        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n",
    "\n",
    "        model_optim = self._select_optimizer()\n",
    "        criterion = self._select_criterion()\n",
    "\n",
    "        if self.args.use_amp:\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "            \n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer = model_optim,\n",
    "                                            steps_per_epoch = train_steps,\n",
    "                                            pct_start = self.args.pct_start,\n",
    "                                            epochs = self.args.train_epochs,\n",
    "                                            max_lr = self.args.learning_rate)\n",
    "\n",
    "        param_count = sum(p.numel() for p in self.model.parameters())\n",
    "\n",
    "        print('parameter_count_test: ', param_count)\n",
    "        \n",
    "        for epoch in range(self.args.train_epochs):\n",
    "            iter_count = 0\n",
    "            train_loss = []\n",
    "\n",
    "            self.model.train()\n",
    "            epoch_time = time.time()\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
    "                iter_count += 1\n",
    "                model_optim.zero_grad()\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                        else:\n",
    "                            if self.args.output_attention:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                            else:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                        f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                        outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                        batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "                        loss = criterion(outputs, batch_y)\n",
    "                        train_loss.append(loss.item())\n",
    "                else:\n",
    "                    if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                    else:\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                            \n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark, batch_y)\n",
    "                    # print(outputs.shape,batch_y.shape)\n",
    "                    f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                    outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                    batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    train_loss.append(loss.item())\n",
    "\n",
    "                if (i + 1) % 100 == 0:\n",
    "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "                    speed = (time.time() - time_now) / iter_count\n",
    "                    left_time = speed * ((self.args.train_epochs - epoch) * train_steps - i)\n",
    "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "                    iter_count = 0\n",
    "                    time_now = time.time()\n",
    "\n",
    "                if self.args.use_amp:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(model_optim)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    model_optim.step()\n",
    "                    \n",
    "                if self.args.lradj == 'TST':\n",
    "                    adjust_learning_rate(model_optim, scheduler, epoch + 1, self.args, printout=False)\n",
    "                    scheduler.step()\n",
    "\n",
    "            print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "            train_loss = np.average(train_loss)\n",
    "            vali_loss = self.vali(vali_data, vali_loader, criterion)\n",
    "            test_loss = self.vali(test_data, test_loader, criterion)\n",
    "\n",
    "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
    "            early_stopping(vali_loss, self.model, path)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "            if self.args.lradj != 'TST':\n",
    "                adjust_learning_rate(model_optim, scheduler, epoch + 1, self.args)\n",
    "            else:\n",
    "                print('Updating learning rate to {}'.format(scheduler.get_last_lr()[0]))\n",
    "\n",
    "        best_model_path = path + '/' + 'checkpoint.pth'\n",
    "        self.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def test(self, setting, test=0):\n",
    "        test_data, test_loader = self._get_data(flag='test')\n",
    "        \n",
    "        if test:\n",
    "            print('loading model')\n",
    "            self.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))\n",
    "\n",
    "        preds = []\n",
    "        trues = []\n",
    "        inputx = []\n",
    "        folder_path = './test_results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        \n",
    "        self.model.eval()\n",
    "        param_count = sum(p.numel() for p in self.model.parameters())\n",
    "\n",
    "        print('parameter_count_test: ', param_count)\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                        else:\n",
    "                            if self.args.output_attention:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                            else:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                    else:\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "\n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                # print(outputs.shape,batch_y.shape)\n",
    "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                batch_y = batch_y.detach().cpu().numpy()\n",
    "\n",
    "                pred = outputs  # outputs.detach().cpu().numpy()  # .squeeze()\n",
    "                true = batch_y  # batch_y.detach().cpu().numpy()  # .squeeze()\n",
    "                print(pred.shape)\n",
    "                preds.append(pred)\n",
    "                trues.append(true)\n",
    "                inputx.append(batch_x.detach().cpu().numpy())\n",
    "                if i % 15 == 0:\n",
    "                    input = batch_x.detach().cpu().numpy()\n",
    "                    gt = np.concatenate((input[0, :, -1], true[0, :, -1]), axis=0)\n",
    "                    pd = np.concatenate((input[0, :, -1], pred[0, :, -1]), axis=0)\n",
    "                    visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))\n",
    "\n",
    "        if self.args.test_flop:\n",
    "            test_params_flop((batch_x.shape[1],batch_x.shape[2]))\n",
    "            exit()\n",
    "        preds = np.array(preds)\n",
    "        trues = np.array(trues)\n",
    "\n",
    "        predss = preds[:,:,-1,-1].flatten()\n",
    "        truess = trues[:,:,-1,-1].flatten()\n",
    "\n",
    "        start_date = '2023-01-01 00:00'\n",
    "        end_date = '2023-12-31 23:00'\n",
    "        \n",
    "        time_index = pandas.date_range(start=start_date, end=end_date, freq='H')\n",
    "\n",
    "        # Adjust the time index to match the length of the data\n",
    "        min_len = min(len(time_index), len(predss))\n",
    "        time_index = time_index[:min_len]\n",
    "        truess = np.roll(truess, 6)\n",
    "        \n",
    "        predss = predss[:min_len]\n",
    "        truess = truess[:min_len]\n",
    "\n",
    "        \n",
    "        #gtt = np.concatenate((time_index, truess), axis = 0)\n",
    "        #pdt = np.concatenate((time_index, predss), axis = 0)\n",
    "        \n",
    "        #visual(gtt, pdt, 'some_file.pdf')\n",
    "        \n",
    "        # Plotting\n",
    "        # Set the font to Times New Roman\n",
    "        plt.rcParams['font.family'] = 'serif'\n",
    "        plt.rcParams['font.size'] = 14  # Increase base font size\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        ax.plot(time_index, predss, label='PatchTST Predictions', color='blue')\n",
    "        ax.plot(time_index, truess, label='Actual height', color='#BB0000')\n",
    "        ax.set_xlabel('Time', fontsize=18)\n",
    "        ax.set_ylabel('Gauge height', fontsize=18)\n",
    "        \n",
    "        ax.set_ylim(-1, 10)\n",
    "        ax.legend(loc='upper left', fontsize=16)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "        \n",
    "        axins1 = inset_axes(ax, width=\"60%\", height=\"40%\", loc='upper right')\n",
    "        axins1.plot(time_index, predss, color='blue')\n",
    "        axins1.plot(time_index, truess, color='#BB0000')\n",
    "        axins1.set_xlabel('time', fontsize=14)\n",
    "        axins1.set_ylabel('Gauge Height', fontsize=14)\n",
    "        \n",
    "        axins1.xaxis.set_major_locator(mdates.DayLocator(interval=5))\n",
    "        axins1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "\n",
    "        #may have to change it\n",
    "        axins1.set_ylim(-1,6)\n",
    "        start_date = pandas.Timestamp('2023-05-01 07:00')  # Adjust date to match your dataset\n",
    "        end_date = pandas.Timestamp('2023-06-02 06:00')  # Adjust date to match your dataset\n",
    "        axins1.set_xlim(start_date, end_date)\n",
    "    \n",
    "        \n",
    "        # Apply mark_inset to show the bounds of the inset on the main plot\n",
    "        mark_inset(ax, axins1, loc1=3, loc2=4, fc=\"none\", ec=\"0.25\")  # Try adjusting loc1 and loc2 here        \n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the figure\n",
    "\n",
    "        # result save\n",
    "        folder_path = './results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        \n",
    "        plt.savefig('PatchTSTfig2.png')  # Update the path as needed\n",
    "        plt.close(fig)\n",
    "\n",
    "        mae, mse, rmse, mape, mspe, rse, corr, wape, nse, pfe, tpe, rfactor, pfactor95 = metric(preds, trues)\n",
    "        print('mse:{}, mae:{}, rse:{}, rmse:{}, wape:{}, nse:{}, pfe:{}, tpe:{}, rfactor:{}, pfactor95:{}'.format(mse, mae, rse, rmse, wape, nse, pfe, tpe, rfactor, pfactor95))\n",
    "        f = open(\"result.txt\", 'a')\n",
    "        f.write(setting + \"  \\n\")\n",
    "        f.write('mse:{}, mae:{}, rse:{}, rmse:{}, wape:{}, nse:{}, pfe:{}, tpe:{}, rfactor:{}, pfactor95:{}'.format(mse, mae, rse, rmse, wape, nse, pfe, tpe, rfactor, pfactor95))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "\n",
    "        # np.save(folder_path + 'metrics.npy', np.array([mae, mse, rmse, mape, mspe,rse, corr]))\n",
    "        np.save(folder_path + 'pred.npy', preds)\n",
    "        # np.save(folder_path + 'true.npy', trues)\n",
    "        # np.save(folder_path + 'x.npy', inputx)\n",
    "        return\n",
    "\n",
    "    def predict(self, setting, load=False):\n",
    "        pred_data, pred_loader = self._get_data(flag='pred')\n",
    "\n",
    "        if load:\n",
    "            path = os.path.join(self.args.checkpoints, setting)\n",
    "            best_model_path = path + '/' + 'checkpoint.pth'\n",
    "            self.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        preds = []\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(pred_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float()\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[2]]).float().to(batch_y.device)\n",
    "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                        else:\n",
    "                            if self.args.output_attention:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                            else:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                        outputs = self.model(batch_x)\n",
    "                    else:\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                pred = outputs.detach().cpu().numpy()  # .squeeze()\n",
    "                preds.append(pred)\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "\n",
    "        # result save\n",
    "        folder_path = './results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        np.save(folder_path + 'real_prediction.npy', preds)\n",
    "\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "367b6acc-eb59-49b6-8e82-9147523e013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "krishna = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a1622-86c2-4202-8dd6-1a0d8bad73b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1e9b090-c4c7-4d2a-a363-e38654f6e7cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Configuration:\n",
      "Model ID: gaze_height_full\n",
      "Model: PatchTST\n",
      "Dataset: gaze_height_full\n",
      "Use GPU: cuda:0\n",
      ">>>>>>> Testing : 24_6_PatchTST_gaze_height_full_ftM_sl24_ll0_pl6_dm16_nh4_el4_dl1_df256_fc1_ebfixed_dtTrue_Exp_0 <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 9413\n",
      "loading model\n",
      "parameter_count_test:  39290\n",
      "(512, 6, 4)\n",
      "(512, 6, 4)\n",
      "(512, 6, 4)\n",
      "(512, 6, 4)\n",
      "(512, 6, 4)\n",
      "(512, 6, 4)\n",
      "(512, 6, 4)\n",
      "(512, 6, 4)\n",
      "(512, 6, 4)\n",
      "(512, 6, 4)\n",
      "(512, 6, 4)\n",
      "(512, 6, 4)\n",
      "(512, 6, 4)\n",
      "(512, 6, 4)\n",
      "(512, 6, 4)\n",
      "(512, 6, 4)\n",
      "(512, 6, 4)\n",
      "(512, 6, 4)\n",
      "mse:0.06604282557964325, mae:0.16744709014892578, rse:0.2693900465965271, rmse:0.256987988948822, wape:21.9400638039372, nse:0.9274289980530739, pfe:0.007449778728187084, tpe:6240, rfactor:0.2693900465965271, pfactor95:11673.555555555555\n"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.random_seed = 2021\n",
    "        self.is_training = 0\n",
    "        self.model_id = 'gaze_height_full'\n",
    "        self.model = 'PatchTST'\n",
    "        self.data = 'gaze_height_full'\n",
    "        self.root_path = './dataset/'\n",
    "        self.data_path = 'chattahoochee_1hr_02336490.csv'\n",
    "        self.features = 'M'\n",
    "        self.target = 'gaze_height'\n",
    "        self.freq = 'h'\n",
    "        self.checkpoints = './checkpoints/'\n",
    "        self.seq_len = 24\n",
    "        self.label_len = 0\n",
    "        self.pred_len = 6 #should be set using loop\n",
    "        self.enc_in = 7\n",
    "        self.e_layers = 4\n",
    "        self.n_heads = 4\n",
    "        self.d_model = 16\n",
    "        self.d_ff = 256\n",
    "        self.dropout = 0.2\n",
    "        self.fc_dropout = 0.2\n",
    "        self.head_dropout = 0\n",
    "        self.patch_len = 8\n",
    "        self.stride = 4\n",
    "        self.des = 'Exp'\n",
    "        self.train_epochs = 40\n",
    "        self.embed = 'fixed'\n",
    "        self.itr = 1 \n",
    "        self.batch_size = 512 \n",
    "        self.learning_rate = 0.002\n",
    "        #fc_dropout = 0.05\n",
    "        #head_dropout = 0.0\n",
    "        #patch_len = 16\n",
    "        #stride = 8\n",
    "        self.padding_patch = 'end'\n",
    "        self.revin = True\n",
    "        self.affine = False\n",
    "        self.subtract_last = 0\n",
    "        self.decomposition = 0\n",
    "        self.kernel_size = 25\n",
    "        self.individual = 0\n",
    "        self.embed_type = 0\n",
    "        #enc_in = 7\n",
    "        #e_layers = 2\n",
    "        self.dec_in = 7\n",
    "        self.c_out = 7\n",
    "        #d_model = 512\n",
    "        #n_heads = 8\n",
    "        self.d_layers = 1\n",
    "        #d_ff = 2048\n",
    "        self.moving_avg = 25\n",
    "        self.factor = 1\n",
    "        self.distil = True\n",
    "        self.dropout = 0.05\n",
    "        self.embed = 'fixed'\n",
    "        self.activation = 'gelu'\n",
    "        self.output_attention = False\n",
    "        self.do_predict = False\n",
    "        self.num_workers = 10\n",
    "        #itr = 2\n",
    "        #train_epochs = 100\n",
    "        #batch_size = 128\n",
    "        self.patience = 6\n",
    "        #learning_rate = 0.0001\n",
    "        #des = 'test'\n",
    "        self.loss = 'mse'\n",
    "        self.lradj = 'type3'\n",
    "        self.pct_start = 0.3\n",
    "        self.use_amp = False\n",
    "        self.use_gpu = torch.cuda.is_available()\n",
    "        self.gpu = 0\n",
    "        self.use_multi_gpu = False\n",
    "        self.devices = '0,1,2,3'\n",
    "        self.test_flop = False\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(args.random_seed)\n",
    "torch.manual_seed(args.random_seed)\n",
    "np.random.seed(args.random_seed)\n",
    "\n",
    "# GPU configuration\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    device_ids = [int(id_) for id_ in args.devices.split(',')]\n",
    "    gpu = device_ids[0]\n",
    "\n",
    "# Print out the experiment settings\n",
    "print('Experiment Configuration:')\n",
    "print('Model ID:', args.model_id)\n",
    "print('Model:', args.model)\n",
    "print('Dataset:', args.data)\n",
    "\n",
    "# Example Experiment Code\n",
    "Exp = Exp_Main  # Assuming Exp_Main is defined elsewhere\n",
    "\n",
    "if args.is_training:\n",
    "    for ii in range(args.itr):\n",
    "        setting = f'{args.model_id}_{args.model}_{args.data}_ft{args.features}_sl{args.seq_len}_ll{args.label_len}_pl{args.pred_len}_dm{args.d_model}_nh{args.n_heads}_el{args.e_layers}_dl{args.d_layers}_df{args.d_ff}_fc{args.factor}_eb{args.embed}_dt{args.distil}_{args.des}_{ii}'\n",
    "        exp = Exp(args)  # Assuming Exp is instantiated with all required settings\n",
    "        print(f'>>>>>>> Start training : {setting} >>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "        trained_model = exp.train(setting)\n",
    "        print(f'>>>>>>> Testing : {setting} <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "        exp.test(setting)\n",
    "\n",
    "        if args.do_predict:\n",
    "            print(f'>>>>>>> Predicting : {setting} <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "            exp.predict(setting, True)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "else:\n",
    "    ii = 0\n",
    "    setting = f'{args.seq_len}_{args.pred_len}_{args.model}_{args.data}_ft{args.features}_sl{args.seq_len}_ll{args.label_len}_pl{args.pred_len}_dm{args.d_model}_nh{args.n_heads}_el{args.e_layers}_dl{args.d_layers}_df{args.d_ff}_fc{args.factor}_eb{args.embed}_dt{args.distil}_{args.des}_{ii}'\n",
    "    exp = Exp(args)  # set experiments\n",
    "    print(f'>>>>>>> Testing : {setting} <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "    exp.test(setting, test=1)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a37cb61d-9519-499e-a8d7-c0bd5294126a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 16702\n",
      "train 121714\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_data, test_loader = exp._get_data(flag='test')\n",
    "\n",
    "train_data, train_loader = exp._get_data(flag='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c253ffb-c0cb-4e4c-b0a3-e52339a9ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "someval1 = next(iter(train_loader))\n",
    "someval2 = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0db6871-7b10-4ead-bdd9-09b93c4474c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "background = someval1[0].float().to(device)\n",
    "tests = someval2[0].float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69867c22-a1d2-424e-bbe0-c9fb9f496322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0263],\n",
       "         [-0.0336],\n",
       "         [-0.0436],\n",
       "         [-0.0516],\n",
       "         [-0.0573],\n",
       "         [-0.0653]],\n",
       "\n",
       "        [[-0.0336],\n",
       "         [-0.0436],\n",
       "         [-0.0516],\n",
       "         [-0.0573],\n",
       "         [-0.0653],\n",
       "         [-0.0746]],\n",
       "\n",
       "        [[-0.0436],\n",
       "         [-0.0516],\n",
       "         [-0.0573],\n",
       "         [-0.0653],\n",
       "         [-0.0746],\n",
       "         [-0.0826]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.3255],\n",
       "         [-0.3277],\n",
       "         [-0.3306],\n",
       "         [-0.3334],\n",
       "         [-0.3370],\n",
       "         [-0.3399]],\n",
       "\n",
       "        [[-0.3277],\n",
       "         [-0.3306],\n",
       "         [-0.3334],\n",
       "         [-0.3370],\n",
       "         [-0.3399],\n",
       "         [-0.3435]],\n",
       "\n",
       "        [[-0.3306],\n",
       "         [-0.3334],\n",
       "         [-0.3370],\n",
       "         [-0.3399],\n",
       "         [-0.3435],\n",
       "         [-0.3464]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "someval2[1].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9ce029c-e24a-44ec-8482-93f7cfe4b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1 = someval2[0][:5,:,:].float().to(device)\n",
    "out1 = exp.model(ss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a763758-d475-41d5-b1ce-61b10b7a8632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0263],\n",
       "         [-0.0336],\n",
       "         [-0.0436],\n",
       "         [-0.0516],\n",
       "         [-0.0573],\n",
       "         [-0.0653]],\n",
       "\n",
       "        [[-0.0336],\n",
       "         [-0.0436],\n",
       "         [-0.0516],\n",
       "         [-0.0573],\n",
       "         [-0.0653],\n",
       "         [-0.0746]],\n",
       "\n",
       "        [[-0.0436],\n",
       "         [-0.0516],\n",
       "         [-0.0573],\n",
       "         [-0.0653],\n",
       "         [-0.0746],\n",
       "         [-0.0826]],\n",
       "\n",
       "        [[-0.0516],\n",
       "         [-0.0573],\n",
       "         [-0.0653],\n",
       "         [-0.0746],\n",
       "         [-0.0826],\n",
       "         [-0.0898]],\n",
       "\n",
       "        [[-0.0573],\n",
       "         [-0.0653],\n",
       "         [-0.0746],\n",
       "         [-0.0826],\n",
       "         [-0.0898],\n",
       "         [-0.0970]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "someval2[1][:5,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe59b758-f5d4-494b-ac9f-69d7b0279ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4007,  0.1089, -0.1788,  0.2372],\n",
       "         [-0.4042,  0.1331, -0.1856,  0.1686],\n",
       "         [-0.4126,  0.1409, -0.1951,  0.1468],\n",
       "         [-0.4267,  0.1347, -0.2096,  0.1169],\n",
       "         [-0.4495,  0.1300, -0.2234,  0.1247],\n",
       "         [-0.4766,  0.1213, -0.2308,  0.1102]],\n",
       "\n",
       "        [[-0.4148,  0.0238, -0.1861,  0.0812],\n",
       "         [-0.4189,  0.0158, -0.1958, -0.0048],\n",
       "         [-0.4354, -0.0082, -0.2156, -0.0261],\n",
       "         [-0.4536, -0.0234, -0.2262, -0.0785],\n",
       "         [-0.4820, -0.0291, -0.2364, -0.0816],\n",
       "         [-0.5046, -0.0343, -0.2300, -0.0931]],\n",
       "\n",
       "        [[-0.4115, -0.0038, -0.1768, -0.0035],\n",
       "         [-0.4196, -0.0197, -0.1833, -0.0793],\n",
       "         [-0.4433, -0.0409, -0.1996, -0.1009],\n",
       "         [-0.4652, -0.0509, -0.2129, -0.1516],\n",
       "         [-0.4833, -0.0492, -0.2207, -0.1584],\n",
       "         [-0.4960, -0.0416, -0.2241, -0.1635]],\n",
       "\n",
       "        [[-0.4251, -0.0630, -0.1795, -0.0767],\n",
       "         [-0.4523, -0.1046, -0.1922, -0.1330],\n",
       "         [-0.4913, -0.1346, -0.2015, -0.1568],\n",
       "         [-0.5190, -0.1500, -0.2087, -0.2024],\n",
       "         [-0.5294, -0.1457, -0.2096, -0.2004],\n",
       "         [-0.5230, -0.1262, -0.2021, -0.1950]],\n",
       "\n",
       "        [[-0.3324,  0.0512, -0.1773, -0.1312],\n",
       "         [-0.3405,  0.0568, -0.1852, -0.1710],\n",
       "         [-0.3625,  0.0702, -0.1896, -0.1975],\n",
       "         [-0.3762,  0.0880, -0.1916, -0.2353],\n",
       "         [-0.3767,  0.1089, -0.1900, -0.2215],\n",
       "         [-0.3670,  0.1333, -0.1793, -0.2020]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e2fe9d8-10e6-49f9-ba75-5124e81a583e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "761f6c6a-54cd-444b-af86-812095cfb1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 6, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "someval1[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d0d8652-fa83-4022-a2a8-2157cc83bbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 24, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "someval1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fd34541-4bac-48c8-b4d6-05b52f641c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0173,  0.0218, -0.1749,  0.8760],\n",
       "         [-0.0440,  0.0218, -0.2441,  0.9025],\n",
       "         [-0.1054,  0.0218, -0.2441,  0.9225],\n",
       "         [-0.1054,  0.0876, -0.2441,  0.9258],\n",
       "         [-0.1667, -0.0440, -0.3132,  0.9125],\n",
       "         [-0.1667,  0.0218, -0.3132,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.3132,  0.8394],\n",
       "         [-0.3507,  0.0218, -0.3132,  0.7896],\n",
       "         [-0.4120,  0.0218, -0.3132,  0.7597],\n",
       "         [-0.3507,  0.1534, -0.3132,  0.7530],\n",
       "         [-0.3507,  0.1534, -0.2441,  0.7796],\n",
       "         [-0.2894,  0.1534, -0.2441,  0.8294],\n",
       "         [-0.2280,  0.2192, -0.1058,  0.8992],\n",
       "         [-0.2894,  0.2192, -0.1749,  0.9557],\n",
       "         [-0.1667,  0.2192, -0.0367,  0.9956],\n",
       "         [-0.2894,  0.1534, -0.1058,  1.0188],\n",
       "         [-0.3507,  0.1534, -0.1749,  1.0122],\n",
       "         [-0.3507,  0.0876, -0.1058,  0.9956],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.9524],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8162],\n",
       "         [-0.4120, -0.1098, -0.1749,  0.7032],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.5005],\n",
       "         [-0.4120,  0.0876, -0.1749,  0.2746]],\n",
       "\n",
       "        [[-0.0440,  0.0218, -0.2441,  0.9025],\n",
       "         [-0.1054,  0.0218, -0.2441,  0.9225],\n",
       "         [-0.1054,  0.0876, -0.2441,  0.9258],\n",
       "         [-0.1667, -0.0440, -0.3132,  0.9125],\n",
       "         [-0.1667,  0.0218, -0.3132,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.3132,  0.8394],\n",
       "         [-0.3507,  0.0218, -0.3132,  0.7896],\n",
       "         [-0.4120,  0.0218, -0.3132,  0.7597],\n",
       "         [-0.3507,  0.1534, -0.3132,  0.7530],\n",
       "         [-0.3507,  0.1534, -0.2441,  0.7796],\n",
       "         [-0.2894,  0.1534, -0.2441,  0.8294],\n",
       "         [-0.2280,  0.2192, -0.1058,  0.8992],\n",
       "         [-0.2894,  0.2192, -0.1749,  0.9557],\n",
       "         [-0.1667,  0.2192, -0.0367,  0.9956],\n",
       "         [-0.2894,  0.1534, -0.1058,  1.0188],\n",
       "         [-0.3507,  0.1534, -0.1749,  1.0122],\n",
       "         [-0.3507,  0.0876, -0.1058,  0.9956],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.9524],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8162],\n",
       "         [-0.4120, -0.1098, -0.1749,  0.7032],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.5005],\n",
       "         [-0.4120,  0.0876, -0.1749,  0.2746],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.0952]],\n",
       "\n",
       "        [[-0.1054,  0.0218, -0.2441,  0.9225],\n",
       "         [-0.1054,  0.0876, -0.2441,  0.9258],\n",
       "         [-0.1667, -0.0440, -0.3132,  0.9125],\n",
       "         [-0.1667,  0.0218, -0.3132,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.3132,  0.8394],\n",
       "         [-0.3507,  0.0218, -0.3132,  0.7896],\n",
       "         [-0.4120,  0.0218, -0.3132,  0.7597],\n",
       "         [-0.3507,  0.1534, -0.3132,  0.7530],\n",
       "         [-0.3507,  0.1534, -0.2441,  0.7796],\n",
       "         [-0.2894,  0.1534, -0.2441,  0.8294],\n",
       "         [-0.2280,  0.2192, -0.1058,  0.8992],\n",
       "         [-0.2894,  0.2192, -0.1749,  0.9557],\n",
       "         [-0.1667,  0.2192, -0.0367,  0.9956],\n",
       "         [-0.2894,  0.1534, -0.1058,  1.0188],\n",
       "         [-0.3507,  0.1534, -0.1749,  1.0122],\n",
       "         [-0.3507,  0.0876, -0.1058,  0.9956],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.9524],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8162],\n",
       "         [-0.4120, -0.1098, -0.1749,  0.7032],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.5005],\n",
       "         [-0.4120,  0.0876, -0.1749,  0.2746],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.0952],\n",
       "         [-0.4120,  0.0218, -0.1749, -0.0277]],\n",
       "\n",
       "        [[-0.1054,  0.0876, -0.2441,  0.9258],\n",
       "         [-0.1667, -0.0440, -0.3132,  0.9125],\n",
       "         [-0.1667,  0.0218, -0.3132,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.3132,  0.8394],\n",
       "         [-0.3507,  0.0218, -0.3132,  0.7896],\n",
       "         [-0.4120,  0.0218, -0.3132,  0.7597],\n",
       "         [-0.3507,  0.1534, -0.3132,  0.7530],\n",
       "         [-0.3507,  0.1534, -0.2441,  0.7796],\n",
       "         [-0.2894,  0.1534, -0.2441,  0.8294],\n",
       "         [-0.2280,  0.2192, -0.1058,  0.8992],\n",
       "         [-0.2894,  0.2192, -0.1749,  0.9557],\n",
       "         [-0.1667,  0.2192, -0.0367,  0.9956],\n",
       "         [-0.2894,  0.1534, -0.1058,  1.0188],\n",
       "         [-0.3507,  0.1534, -0.1749,  1.0122],\n",
       "         [-0.3507,  0.0876, -0.1058,  0.9956],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.9524],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8162],\n",
       "         [-0.4120, -0.1098, -0.1749,  0.7032],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.5005],\n",
       "         [-0.4120,  0.0876, -0.1749,  0.2746],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.0952],\n",
       "         [-0.4120,  0.0218, -0.1749, -0.0277],\n",
       "         [-0.4120, -0.0440, -0.1749, -0.1041]],\n",
       "\n",
       "        [[-0.1667, -0.0440, -0.3132,  0.9125],\n",
       "         [-0.1667,  0.0218, -0.3132,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.3132,  0.8394],\n",
       "         [-0.3507,  0.0218, -0.3132,  0.7896],\n",
       "         [-0.4120,  0.0218, -0.3132,  0.7597],\n",
       "         [-0.3507,  0.1534, -0.3132,  0.7530],\n",
       "         [-0.3507,  0.1534, -0.2441,  0.7796],\n",
       "         [-0.2894,  0.1534, -0.2441,  0.8294],\n",
       "         [-0.2280,  0.2192, -0.1058,  0.8992],\n",
       "         [-0.2894,  0.2192, -0.1749,  0.9557],\n",
       "         [-0.1667,  0.2192, -0.0367,  0.9956],\n",
       "         [-0.2894,  0.1534, -0.1058,  1.0188],\n",
       "         [-0.3507,  0.1534, -0.1749,  1.0122],\n",
       "         [-0.3507,  0.0876, -0.1058,  0.9956],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.9524],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8162],\n",
       "         [-0.4120, -0.1098, -0.1749,  0.7032],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.5005],\n",
       "         [-0.4120,  0.0876, -0.1749,  0.2746],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.0952],\n",
       "         [-0.4120,  0.0218, -0.1749, -0.0277],\n",
       "         [-0.4120, -0.0440, -0.1749, -0.1041],\n",
       "         [-0.3507,  0.0218, -0.1749, -0.1506]]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests[:5,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fabbce65-d3ba-44c9-b8d6-df02db005ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = exp.model(background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21029b4b-d80e-4bb9-8ce9-fb8ac8e45110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 6, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "926b452b-e03c-4662-9d56-8bc3827b72ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 24, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "594c0769-7e21-45b3-9590-485f8b63e3e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 23\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#masker = shap.maskers.Tabular(background_np, hclustering='correlation')\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Create the SHAP explainer using the model function and the masker\u001b[39;00m\n\u001b[1;32m     22\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mExplainer(f, background_np)\n\u001b[0;32m---> 23\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_np\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cenv/lib/python3.10/site-packages/shap/explainers/_permutation.py:79\u001b[0m, in \u001b[0;36mPermutationExplainer.__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, main_effects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, error_bounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     76\u001b[0m              outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Explain the output of the model on the given arguments.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_effects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmain_effects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_bounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cenv/lib/python3.10/site-packages/shap/explainers/_explainer.py:267\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(args))]\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_args \u001b[38;5;129;01min\u001b[39;00m show_progress(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39margs), num_rows, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m explainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent):\n\u001b[0;32m--> 267\u001b[0m     row_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_row\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrow_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_effects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmain_effects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(row_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    272\u001b[0m     output_indices\u001b[38;5;241m.\u001b[39mappend(row_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_indices\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "File \u001b[0;32m~/.conda/envs/cenv/lib/python3.10/site-packages/shap/explainers/_permutation.py:137\u001b[0m, in \u001b[0;36mPermutationExplainer.explain_row\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *row_args)\u001b[0m\n\u001b[1;32m    134\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# evaluate the masked model\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     row_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(fm),) \u001b[38;5;241m+\u001b[39m outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[0;32m~/.conda/envs/cenv/lib/python3.10/site-packages/shap/utils/_masked_model.py:66\u001b[0m, in \u001b[0;36mMaskedModel.__call__\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m     64\u001b[0m         full_masks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39msum(masks \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_masker_cols), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m     65\u001b[0m         _convert_delta_mask_to_full(masks, full_masks)\n\u001b[0;32m---> 66\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_full_masking_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_full_masking_call(masks, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "File \u001b[0;32m~/.conda/envs/cenv/lib/python3.10/site-packages/shap/utils/_masked_model.py:95\u001b[0m, in \u001b[0;36mMaskedModel._full_masking_call\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m     93\u001b[0m     masked_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasker(delta_ind, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     masked_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# get a copy that won't get overwritten by the next iteration\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasker, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimmutable_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    x = torch.from_numpy().to(device)\n",
    "    out = exp.model(x)\n",
    "    return out[:, 5, 2].numpy()\n",
    "\n",
    "\n",
    "def time_series_masker(data, mask):\n",
    "    # Replace masked elements with the mean of the series (simplified approach)\n",
    "    masked_data = data.copy()\n",
    "    masked_data[mask] = np.mean(data, axis=0)\n",
    "    return masked_data\n",
    "\n",
    "# Convert background to a NumPy array if it's not already\n",
    "background_np = background.cpu().detach().numpy()\n",
    "test_np = tests.cpu().detach().numpy()\n",
    "# Create a masker that uses the background data for replacing \"masked\" features\n",
    "masker = shap.maskers.Independent(data=background_np)\n",
    "#masker = shap.maskers.Tabular(background_np, hclustering='correlation')\n",
    "\n",
    "\n",
    "# Create the SHAP explainer using the model function and the masker\n",
    "explainer = shap.Explainer(f, background_np)\n",
    "shap_values = explainer(test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b1ad5a56-5b49-43ad-90ce-e63be120f16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 24, 3)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8aa3d1f8-3fd8-4670-87eb-35f958622b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 24, 3)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8764b-9c94-4e31-b956-c3759217e2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95c77f5-cade-485f-8b64-29ca22ff8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2023-01-01 00:00'\n",
    "end_date = '2023-12-31 23:00'\n",
    "        \n",
    "time_index = pd.date_range(start=start_date, end=end_date, freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bb59532-5574-4672-8a40-c9ecddd2dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResults(predss, truess, model_name, start_date='2023-01-01 00:00', end_date = '2023-12-31 23:00'):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.dates as mdates\n",
    "    from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
    "\n",
    "    time_index = pandas.date_range(start=start_date, end=end_date, freq='H')\n",
    "\n",
    "    # Adjust the time index to match the length of the data\n",
    "    min_len = min(len(time_index), len(predss))\n",
    "    time_index = time_index[:min_len]\n",
    "    truess = np.roll(truess, 6)\n",
    "    \n",
    "    predss = predss[:min_len]\n",
    "    truess = truess[:min_len]\n",
    "\n",
    "    \n",
    "    #gtt = np.concatenate((time_index, truess), axis = 0)\n",
    "    #pdt = np.concatenate((time_index, predss), axis = 0)\n",
    "    \n",
    "    #visual(gtt, pdt, 'some_file.pdf')\n",
    "    \n",
    "    # Plotting\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    plt.title('{0} Model Predictions with a 6-Hour Forecast Horizon for year 2023'.format(model_name))\n",
    "    \n",
    "    ax.plot(time_index, predss, label='{0} Predictions'.format(model_name), color='blue')\n",
    "    ax.plot(time_index, truess, label='Actual height', color='#BB0000')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Gaze height')\n",
    "    \n",
    "    ax.set_ylim(-1, 10)\n",
    "    ax.legend(loc='upper left')\n",
    "    \n",
    "    axins1 = inset_axes(ax, width=\"60%\", height=\"40%\", loc='upper right')\n",
    "    axins1.plot(time_index, predss, color='blue')\n",
    "    axins1.plot(time_index, truess, color='#BB0000')\n",
    "    axins1.set_xlabel('time')\n",
    "    axins1.set_ylabel('Gaze Height')\n",
    "\n",
    "    axins1.xaxis.set_major_locator(mdates.DayLocator(interval=5))\n",
    "    axins1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "\n",
    "    #may have to change it\n",
    "    axins1.set_ylim(-1,6)\n",
    "    start_date = pandas.Timestamp('2023-05-01')  # Adjust date to match the dataset\n",
    "    end_date = pandas.Timestamp('2023-06-01')  # Adjust date to match the dataset\n",
    "    axins1.set_xlim(start_date, end_date)\n",
    "\n",
    "    \n",
    "    # Apply mark_inset to show the bounds of the inset on the main plot\n",
    "    mark_inset(ax, axins1, loc1=3, loc2=4, fc=\"none\", ec=\"0.25\")      \n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    \n",
    "    plt.savefig('Results.png') \n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3011204-64e3-4df8-a905-305822c8e317",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y can be no greater than 2D, but have shapes (5,) and (5, 6, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplotResults\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mss1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPatchTST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2023-01-01 00:00\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2023-12-31 23:00\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m, in \u001b[0;36mplotResults\u001b[0;34m(predss, truess, model_name, start_date, end_date)\u001b[0m\n\u001b[1;32m     24\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m     25\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m Model Predictions with a 6-Hour Forecast Horizon for year 2023\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_name))\n\u001b[0;32m---> 27\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m Predictions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m ax\u001b[38;5;241m.\u001b[39mplot(time_index, truess, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual height\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#BB0000\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/cenv/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1721\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/.conda/envs/cenv/lib/python3.10/site-packages/matplotlib/axes/_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cenv/lib/python3.10/site-packages/matplotlib/axes/_base.py:502\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    505\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "\u001b[0;31mValueError\u001b[0m: x and y can be no greater than 2D, but have shapes (5,) and (5, 6, 1)"
     ]
    }
   ],
   "source": [
    "plotResults(out1.detach().cpu().numpy(), ss1.detach().cpu().numpy(), 'PatchTST', start_date='2023-01-01 00:00', end_date = '2023-12-31 23:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3fda69-4cab-42c5-a749-d805580fb7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e06982-f72f-4de0-998d-5e106ec5cd5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
