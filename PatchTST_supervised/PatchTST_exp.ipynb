{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80297306-cc2e-40fb-a534-e5bf05b8b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_provider.data_factory import data_provider\n",
    "from exp.exp_basic import Exp_Basic\n",
    "from models import Informer, Autoformer, Transformer, DLinear, Linear, NLinear, PatchTST\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate, visual, test_params_flop\n",
    "from utils.metrics import metric\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler \n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Exp_Main(Exp_Basic):\n",
    "    def __init__(self, args):\n",
    "        super(Exp_Main, self).__init__(args)\n",
    "\n",
    "    def _build_model(self):\n",
    "        model_dict = {\n",
    "            'Autoformer': Autoformer,\n",
    "            'Transformer': Transformer,\n",
    "            'Informer': Informer,\n",
    "            'DLinear': DLinear,\n",
    "            'NLinear': NLinear,\n",
    "            'Linear': Linear,\n",
    "            'PatchTST': PatchTST,\n",
    "        }\n",
    "        model = model_dict[self.args.model].Model(self.args).float()\n",
    "\n",
    "        if self.args.use_multi_gpu and self.args.use_gpu:\n",
    "            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n",
    "        return model\n",
    "\n",
    "    def _get_data(self, flag):\n",
    "        data_set, data_loader = data_provider(self.args, flag)\n",
    "        return data_set, data_loader\n",
    "\n",
    "    def _select_optimizer(self):\n",
    "        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
    "        return model_optim\n",
    "\n",
    "    def _select_criterion(self):\n",
    "        criterion = nn.MSELoss()\n",
    "        return criterion\n",
    "\n",
    "    def vali(self, vali_data, vali_loader, criterion):\n",
    "        total_loss = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float()\n",
    "\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                        else:\n",
    "                            if self.args.output_attention:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                            else:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                        outputs = self.model(batch_x)\n",
    "                    else:\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "\n",
    "                pred = outputs.detach().cpu()\n",
    "                true = batch_y.detach().cpu()\n",
    "\n",
    "                loss = criterion(pred, true)\n",
    "\n",
    "                total_loss.append(loss)\n",
    "        total_loss = np.average(total_loss)\n",
    "        self.model.train()\n",
    "        return total_loss\n",
    "\n",
    "    def train(self, setting):\n",
    "        train_data, train_loader = self._get_data(flag='train')\n",
    "        vali_data, vali_loader = self._get_data(flag='val')\n",
    "        test_data, test_loader = self._get_data(flag='test')\n",
    "\n",
    "        path = os.path.join(self.args.checkpoints, setting)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        time_now = time.time()\n",
    "\n",
    "        train_steps = len(train_loader)\n",
    "        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n",
    "\n",
    "        model_optim = self._select_optimizer()\n",
    "        criterion = self._select_criterion()\n",
    "\n",
    "        if self.args.use_amp:\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "            \n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer = model_optim,\n",
    "                                            steps_per_epoch = train_steps,\n",
    "                                            pct_start = self.args.pct_start,\n",
    "                                            epochs = self.args.train_epochs,\n",
    "                                            max_lr = self.args.learning_rate)\n",
    "\n",
    "        param_count = sum(p.numel() for p in self.model.parameters())\n",
    "\n",
    "        print('parameter_count_test: ', param_count)\n",
    "        \n",
    "        for epoch in range(self.args.train_epochs):\n",
    "            iter_count = 0\n",
    "            train_loss = []\n",
    "\n",
    "            self.model.train()\n",
    "            epoch_time = time.time()\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
    "                iter_count += 1\n",
    "                model_optim.zero_grad()\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                        else:\n",
    "                            if self.args.output_attention:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                            else:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                        f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                        outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                        batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "                        loss = criterion(outputs, batch_y)\n",
    "                        train_loss.append(loss.item())\n",
    "                else:\n",
    "                    if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                    else:\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                            \n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark, batch_y)\n",
    "                    # print(outputs.shape,batch_y.shape)\n",
    "                    f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                    outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                    batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    train_loss.append(loss.item())\n",
    "\n",
    "                if (i + 1) % 100 == 0:\n",
    "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "                    speed = (time.time() - time_now) / iter_count\n",
    "                    left_time = speed * ((self.args.train_epochs - epoch) * train_steps - i)\n",
    "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "                    iter_count = 0\n",
    "                    time_now = time.time()\n",
    "\n",
    "                if self.args.use_amp:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(model_optim)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    model_optim.step()\n",
    "                    \n",
    "                if self.args.lradj == 'TST':\n",
    "                    adjust_learning_rate(model_optim, scheduler, epoch + 1, self.args, printout=False)\n",
    "                    scheduler.step()\n",
    "\n",
    "            print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "            train_loss = np.average(train_loss)\n",
    "            vali_loss = self.vali(vali_data, vali_loader, criterion)\n",
    "            test_loss = self.vali(test_data, test_loader, criterion)\n",
    "\n",
    "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
    "            early_stopping(vali_loss, self.model, path)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "            if self.args.lradj != 'TST':\n",
    "                adjust_learning_rate(model_optim, scheduler, epoch + 1, self.args)\n",
    "            else:\n",
    "                print('Updating learning rate to {}'.format(scheduler.get_last_lr()[0]))\n",
    "\n",
    "        best_model_path = path + '/' + 'checkpoint.pth'\n",
    "        self.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def test(self, setting, test=0):\n",
    "        test_data, test_loader = self._get_data(flag='test')\n",
    "        \n",
    "        if test:\n",
    "            print('loading model')\n",
    "            self.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))\n",
    "\n",
    "        preds = []\n",
    "        trues = []\n",
    "        inputx = []\n",
    "        folder_path = './test_results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        \n",
    "        self.model.eval()\n",
    "        param_count = sum(p.numel() for p in self.model.parameters())\n",
    "\n",
    "        print('parameter_count_test: ', param_count)\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                        else:\n",
    "                            if self.args.output_attention:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                            else:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                    else:\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "\n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                # print(outputs.shape,batch_y.shape)\n",
    "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                batch_y = batch_y.detach().cpu().numpy()\n",
    "\n",
    "                pred = outputs  # outputs.detach().cpu().numpy()  # .squeeze()\n",
    "                true = batch_y  # batch_y.detach().cpu().numpy()  # .squeeze()\n",
    "                print(pred.shape)\n",
    "                preds.append(pred)\n",
    "                trues.append(true)\n",
    "                inputx.append(batch_x.detach().cpu().numpy())\n",
    "                if i % 15 == 0:\n",
    "                    input = batch_x.detach().cpu().numpy()\n",
    "                    gt = np.concatenate((input[0, :, -1], true[0, :, -1]), axis=0)\n",
    "                    pd = np.concatenate((input[0, :, -1], pred[0, :, -1]), axis=0)\n",
    "                    visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))\n",
    "\n",
    "        if self.args.test_flop:\n",
    "            test_params_flop((batch_x.shape[1],batch_x.shape[2]))\n",
    "            exit()\n",
    "        preds = np.array(preds)\n",
    "        trues = np.array(trues)\n",
    "        \n",
    "        predss = preds[:,:,-1,-1].flatten()\n",
    "        truess = trues[:,:,-1,-1].flatten()\n",
    "\n",
    "        start_date = '2023-01-01 00:00'\n",
    "        end_date = '2023-12-31 23:00'\n",
    "        \n",
    "        time_index = pandas.date_range(start=start_date, end=end_date, freq='H')\n",
    "\n",
    "        # Adjust the time index to match the length of the data\n",
    "        time_index = time_index[:len(predss)]\n",
    "        \n",
    "        #gtt = np.concatenate((time_index, truess), axis = 0)\n",
    "        #pdt = np.concatenate((time_index, predss), axis = 0)\n",
    "        \n",
    "        #visual(gtt, pdt, 'some_file.pdf')\n",
    "        \n",
    "        # Plotting\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        plt.plot(time_index, predss, label='PatchTST Predictions', color='blue')\n",
    "        plt.plot(time_index, truess, label='Actual height', color='#BB0000', linestyle='--')\n",
    "        plt.xlabel('time')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Save the figure\n",
    "\n",
    "        # result save\n",
    "        folder_path = './results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "            \n",
    "        plt.savefig('PatchTSTfig2.png')  # Update the path as needed\n",
    "\n",
    "        mae, mse, rmse, mape, mspe, rse, corr, wape, nse = metric(preds, trues)\n",
    "        print('mse:{}, mae:{}, rse:{}, wape:{}, nse:{}'.format(mse, mae, rse, wape, nse))\n",
    "        f = open(\"result.txt\", 'a')\n",
    "        f.write(setting + \"  \\n\")\n",
    "        f.write('mse:{}, mae:{}, rse:{}, wape:{}, nse:{}'.format(mse, mae, rse, wape, nse))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "\n",
    "        # np.save(folder_path + 'metrics.npy', np.array([mae, mse, rmse, mape, mspe,rse, corr]))\n",
    "        np.save(folder_path + 'pred.npy', preds)\n",
    "        # np.save(folder_path + 'true.npy', trues)\n",
    "        # np.save(folder_path + 'x.npy', inputx)\n",
    "        return\n",
    "\n",
    "    def predict(self, setting, load=False):\n",
    "        pred_data, pred_loader = self._get_data(flag='pred')\n",
    "\n",
    "        if load:\n",
    "            path = os.path.join(self.args.checkpoints, setting)\n",
    "            best_model_path = path + '/' + 'checkpoint.pth'\n",
    "            self.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        preds = []\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(pred_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float()\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[2]]).float().to(batch_y.device)\n",
    "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                        else:\n",
    "                            if self.args.output_attention:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                            else:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                        outputs = self.model(batch_x)\n",
    "                    else:\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                pred = outputs.detach().cpu().numpy()  # .squeeze()\n",
    "                preds.append(pred)\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "\n",
    "        # result save\n",
    "        folder_path = './results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        np.save(folder_path + 'real_prediction.npy', preds)\n",
    "\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "367b6acc-eb59-49b6-8e82-9147523e013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "krishna = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a1622-86c2-4202-8dd6-1a0d8bad73b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1e9b090-c4c7-4d2a-a363-e38654f6e7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Configuration:\n",
      "Model ID: gaze_height\n",
      "Model: PatchTST\n",
      "Dataset: gaze_height\n",
      "Use GPU: cuda:0\n",
      ">>>>>>> Testing : gaze_height_PatchTST_gaze_height_ftM_sl24_ll0_pl6_dm16_nh4_el4_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0 <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 9199\n",
      "loading model\n",
      "parameter_count_test:  22394\n",
      "(512, 6, 3)\n",
      "(512, 6, 3)\n",
      "(512, 6, 3)\n",
      "(512, 6, 3)\n",
      "(512, 6, 3)\n",
      "(512, 6, 3)\n",
      "(512, 6, 3)\n",
      "(512, 6, 3)\n",
      "(512, 6, 3)\n",
      "(512, 6, 3)\n",
      "(512, 6, 3)\n",
      "(512, 6, 3)\n",
      "(512, 6, 3)\n",
      "(512, 6, 3)\n",
      "(512, 6, 3)\n",
      "(512, 6, 3)\n",
      "(512, 6, 3)\n",
      "mse:0.03732313588261604, mae:0.06441798061132431, rse:0.20613521337509155, wape:8.35963408201705, nse:0.957508273422718\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.random_seed = 2021\n",
    "        self.is_training = 0\n",
    "        self.model_id = 'gaze_height'\n",
    "        self.model = 'PatchTST'\n",
    "        self.data = 'gaze_height'\n",
    "        self.root_path = './dataset/'\n",
    "        self.data_path = 'gaze_height_CHATTAHOOCHEE_02336000.csv'\n",
    "        self.features = 'M'\n",
    "        self.target = 'gaze_height'\n",
    "        self.freq = 'h'\n",
    "        self.checkpoints = './checkpoints/'\n",
    "        self.seq_len = 24\n",
    "        self.label_len = 0\n",
    "        self.pred_len = 6 #should be set using loop\n",
    "        self.enc_in = 7\n",
    "        self.e_layers = 4\n",
    "        self.n_heads = 4\n",
    "        self.d_model = 16\n",
    "        self.d_ff = 128\n",
    "        self.dropout = 0.2\n",
    "        self.fc_dropout = 0.2\n",
    "        self.head_dropout = 0\n",
    "        self.patch_len = 8\n",
    "        self.stride = 4\n",
    "        self.des = 'Exp'\n",
    "        self.train_epochs = 40\n",
    "        self.embed = 'fixed'\n",
    "        self.itr = 1 \n",
    "        self.batch_size = 512 \n",
    "        self.learning_rate = 0.002\n",
    "        #fc_dropout = 0.05\n",
    "        #head_dropout = 0.0\n",
    "        #patch_len = 16\n",
    "        #stride = 8\n",
    "        self.padding_patch = 'end'\n",
    "        self.revin = True\n",
    "        self.affine = False\n",
    "        self.subtract_last = 0\n",
    "        self.decomposition = 0\n",
    "        self.kernel_size = 25\n",
    "        self.individual = 0\n",
    "        self.embed_type = 0\n",
    "        #enc_in = 7\n",
    "        #e_layers = 2\n",
    "        self.dec_in = 7\n",
    "        self.c_out = 7\n",
    "        #d_model = 512\n",
    "        #n_heads = 8\n",
    "        self.d_layers = 1\n",
    "        #d_ff = 2048\n",
    "        self.moving_avg = 25\n",
    "        self.factor = 1\n",
    "        self.distil = True\n",
    "        self.dropout = 0.05\n",
    "        self.embed = 'timeF'\n",
    "        self.activation = 'gelu'\n",
    "        self.output_attention = False\n",
    "        self.do_predict = False\n",
    "        self.num_workers = 10\n",
    "        #itr = 2\n",
    "        #train_epochs = 100\n",
    "        #batch_size = 128\n",
    "        self.patience = 6\n",
    "        #learning_rate = 0.0001\n",
    "        #des = 'test'\n",
    "        self.loss = 'mse'\n",
    "        self.lradj = 'type3'\n",
    "        self.pct_start = 0.3\n",
    "        self.use_amp = False\n",
    "        self.use_gpu = torch.cuda.is_available()\n",
    "        self.gpu = 0\n",
    "        self.use_multi_gpu = False\n",
    "        self.devices = '0,1,2,3'\n",
    "        self.test_flop = False\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(args.random_seed)\n",
    "torch.manual_seed(args.random_seed)\n",
    "np.random.seed(args.random_seed)\n",
    "\n",
    "# GPU configuration\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    device_ids = [int(id_) for id_ in args.devices.split(',')]\n",
    "    gpu = device_ids[0]\n",
    "\n",
    "# Print out the experiment settings\n",
    "print('Experiment Configuration:')\n",
    "print('Model ID:', args.model_id)\n",
    "print('Model:', args.model)\n",
    "print('Dataset:', args.data)\n",
    "\n",
    "# Example Experiment Code\n",
    "Exp = Exp_Main  # Assuming Exp_Main is defined elsewhere\n",
    "\n",
    "if args.is_training:\n",
    "    for ii in range(args.itr):\n",
    "        setting = f'{args.model_id}_{args.model}_{args.data}_ft{args.features}_sl{args.seq_len}_ll{args.label_len}_pl{args.pred_len}_dm{args.d_model}_nh{args.n_heads}_el{args.e_layers}_dl{args.d_layers}_df{args.d_ff}_fc{args.factor}_eb{args.embed}_dt{args.distil}_{args.des}_{ii}'\n",
    "        exp = Exp(args)  # Assuming Exp is instantiated with all required settings\n",
    "        print(f'>>>>>>> Start training : {setting} >>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "        exp.train(setting)\n",
    "        print(f'>>>>>>> Testing : {setting} <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "        exp.test(setting)\n",
    "\n",
    "        if args.do_predict:\n",
    "            print(f'>>>>>>> Predicting : {setting} <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "            exp.predict(setting, True)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "else:\n",
    "    ii = 0\n",
    "    setting = f'{args.model_id}_{args.model}_{args.data}_ft{args.features}_sl{args.seq_len}_ll{args.label_len}_pl{args.pred_len}_dm{args.d_model}_nh{args.n_heads}_el{args.e_layers}_dl{args.d_layers}_df{args.d_ff}_fc{args.factor}_eb{args.embed}_dt{args.distil}_{args.des}_{ii}'\n",
    "    exp = Exp(args)  # set experiments\n",
    "    print(f'>>>>>>> Testing : {setting} <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "    exp.test(setting, test=1)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a37cb61d-9519-499e-a8d7-c0bd5294126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[[1,2,3],[1,2,4]],[[1,2,5],[1,2,6]]]\n",
    "b = [[[1,2,1],[1,2,2]],[[1,2,3],[1,2,4]]]\n",
    "c = np.array([a,b])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c253ffb-c0cb-4e4c-b0a3-e52339a9ebf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3],\n",
       "        [5]],\n",
       "\n",
       "       [[1],\n",
       "        [3]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,:,[0], -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d0d8652-fa83-4022-a2a8-2157cc83bbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, :, -1].flatten()\n",
    "#a[:,:,:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "594c0769-7e21-45b3-9590-485f8b63e3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 2, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95c77f5-cade-485f-8b64-29ca22ff8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2023-01-01 00:00'\n",
    "end_date = '2023-12-31 23:00'\n",
    "        \n",
    "time_index = pd.date_range(start=start_date, end=end_date, freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb59532-5574-4672-8a40-c9ecddd2dd5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
