{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80297306-cc2e-40fb-a534-e5bf05b8b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_provider.data_factory import data_provider\n",
    "from exp.exp_basic import Exp_Basic\n",
    "from models import Informer, Autoformer, Transformer, DLinear, Linear, NLinear, PatchTST\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate, visual, test_params_flop\n",
    "from utils.metrics import metric\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler \n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Exp_Main(Exp_Basic):\n",
    "    def __init__(self, args):\n",
    "        super(Exp_Main, self).__init__(args)\n",
    "\n",
    "    def _build_model(self):\n",
    "        model_dict = {\n",
    "            'Autoformer': Autoformer,\n",
    "            'Transformer': Transformer,\n",
    "            'Informer': Informer,\n",
    "            'DLinear': DLinear,\n",
    "            'NLinear': NLinear,\n",
    "            'Linear': Linear,\n",
    "            'PatchTST': PatchTST,\n",
    "        }\n",
    "        model = model_dict[self.args.model].Model(self.args).float()\n",
    "\n",
    "        if self.args.use_multi_gpu and self.args.use_gpu:\n",
    "            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n",
    "        return model\n",
    "\n",
    "    def _get_data(self, flag):\n",
    "        print('get data')\n",
    "        data_set, data_loader = data_provider(self.args, flag)\n",
    "        print('gotten data')\n",
    "        return data_set, data_loader\n",
    "\n",
    "    def _select_optimizer(self):\n",
    "        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
    "        return model_optim\n",
    "\n",
    "    def _select_criterion(self):\n",
    "        criterion = nn.MSELoss()\n",
    "        return criterion\n",
    "\n",
    "    def vali(self, vali_data, vali_loader, criterion):\n",
    "        total_loss = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float()\n",
    "\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                        else:\n",
    "                            if self.args.output_attention:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                            else:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                        outputs = self.model(batch_x)\n",
    "                    else:\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "\n",
    "                pred = outputs.detach().cpu()\n",
    "                true = batch_y.detach().cpu()\n",
    "\n",
    "                loss = criterion(pred, true)\n",
    "\n",
    "                total_loss.append(loss)\n",
    "        total_loss = np.average(total_loss)\n",
    "        self.model.train()\n",
    "        return total_loss\n",
    "\n",
    "    def train(self, setting):\n",
    "        train_data, train_loader = self._get_data(flag='train')\n",
    "        vali_data, vali_loader = self._get_data(flag='val')\n",
    "        test_data, test_loader = self._get_data(flag='test')\n",
    "\n",
    "        path = os.path.join(self.args.checkpoints, setting)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        time_now = time.time()\n",
    "\n",
    "        train_steps = len(train_loader)\n",
    "        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n",
    "\n",
    "        model_optim = self._select_optimizer()\n",
    "        criterion = self._select_criterion()\n",
    "\n",
    "        if self.args.use_amp:\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "            \n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer = model_optim,\n",
    "                                            steps_per_epoch = train_steps,\n",
    "                                            pct_start = self.args.pct_start,\n",
    "                                            epochs = self.args.train_epochs,\n",
    "                                            max_lr = self.args.learning_rate)\n",
    "\n",
    "        param_count = sum(p.numel() for p in self.model.parameters())\n",
    "\n",
    "        print('parameter_count_test: ', param_count)\n",
    "        \n",
    "        for epoch in range(self.args.train_epochs):\n",
    "            iter_count = 0\n",
    "            train_loss = []\n",
    "\n",
    "            self.model.train()\n",
    "            epoch_time = time.time()\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
    "                iter_count += 1\n",
    "                model_optim.zero_grad()\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                        else:\n",
    "                            if self.args.output_attention:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                            else:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                        f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                        outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                        batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "                        loss = criterion(outputs, batch_y)\n",
    "                        train_loss.append(loss.item())\n",
    "                else:\n",
    "                    if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                    else:\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                            \n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark, batch_y)\n",
    "                    # print(outputs.shape,batch_y.shape)\n",
    "                    f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                    outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                    batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    train_loss.append(loss.item())\n",
    "\n",
    "                if (i + 1) % 100 == 0:\n",
    "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "                    speed = (time.time() - time_now) / iter_count\n",
    "                    left_time = speed * ((self.args.train_epochs - epoch) * train_steps - i)\n",
    "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "                    iter_count = 0\n",
    "                    time_now = time.time()\n",
    "\n",
    "                if self.args.use_amp:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(model_optim)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    model_optim.step()\n",
    "                    \n",
    "                if self.args.lradj == 'TST':\n",
    "                    adjust_learning_rate(model_optim, scheduler, epoch + 1, self.args, printout=False)\n",
    "                    scheduler.step()\n",
    "\n",
    "            print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "            train_loss = np.average(train_loss)\n",
    "            vali_loss = self.vali(vali_data, vali_loader, criterion)\n",
    "            test_loss = self.vali(test_data, test_loader, criterion)\n",
    "\n",
    "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
    "            early_stopping(vali_loss, self.model, path)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "            if self.args.lradj != 'TST':\n",
    "                adjust_learning_rate(model_optim, scheduler, epoch + 1, self.args)\n",
    "            else:\n",
    "                print('Updating learning rate to {}'.format(scheduler.get_last_lr()[0]))\n",
    "\n",
    "        best_model_path = path + '/' + 'checkpoint.pth'\n",
    "        self.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def saveData(self, y, y_pred, start_time, end_time, hrs):  \n",
    "        print(len(y), len(y_pred))\n",
    "        time_index = pandas.date_range(start=start_time, end=end_time, freq='H')\n",
    "        time_index = time_index[:len(y)]\n",
    "        # if len(y) != len(time_index):\n",
    "        #     raise ValueError(f\"Length of y ({len(y)}) does not match number of time steps ({len(time_index)}).\")\n",
    "        # if len(y_pred) != len(time_index):\n",
    "        #     raise ValueError(f\"Length of y_pred ({len(y_pred)}) does not match number of time steps ({len(time_index)}).\")\n",
    "        df = pandas.DataFrame({\n",
    "            'y': y,\n",
    "            'y_pred': y_pred\n",
    "        }, index=time_index)\n",
    "        \n",
    "        df = df.reset_index().rename(columns={'index': 'DATE'})\n",
    "        df.to_csv(f'data_results/patchtst_predictions_bigpatch_bigmodel_{hrs}.csv')\n",
    "\n",
    "\n",
    "    \n",
    "    def test(self, setting, test=0):\n",
    "        save_data = True\n",
    "        pred_len = 1\n",
    "        test_data, test_loader = self._get_data(flag='test')\n",
    "        \n",
    "        if test:\n",
    "            print('loading model')\n",
    "            self.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))\n",
    "\n",
    "        preds = []\n",
    "        trues = []\n",
    "        inputx = []\n",
    "        folder_path = './test_results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        \n",
    "        self.model.eval()\n",
    "        param_count = sum(p.numel() for p in self.model.parameters())\n",
    "\n",
    "        print('parameter_count_test: ', param_count)\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                        else:\n",
    "                            if self.args.output_attention:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                            else:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                    else:\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "\n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                # print(outputs.shape,batch_y.shape)\n",
    "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                batch_y = batch_y.detach().cpu().numpy()\n",
    "\n",
    "                pred = outputs  # outputs.detach().cpu().numpy()  # .squeeze()\n",
    "                true = batch_y  # batch_y.detach().cpu().numpy()  # .squeeze()\n",
    "                print(pred.shape)\n",
    "                preds.append(pred)\n",
    "                trues.append(true)\n",
    "                inputx.append(batch_x.detach().cpu().numpy())\n",
    "                if i % 15 == 0:\n",
    "                    input = batch_x.detach().cpu().numpy()\n",
    "                    gt = np.concatenate((input[0, :, -1], true[0, :, -1]), axis=0)\n",
    "                    pd = np.concatenate((input[0, :, -1], pred[0, :, -1]), axis=0)\n",
    "                    visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))\n",
    "\n",
    "        if self.args.test_flop:\n",
    "            test_params_flop((batch_x.shape[1],batch_x.shape[2]))\n",
    "            exit()\n",
    "            \n",
    "        folder_path = './results/' + setting + '/'\n",
    "        # result save\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "            \n",
    "        preds = np.array(preds)\n",
    "        trues = np.array(trues)\n",
    "\n",
    "        predss = preds[:,:,-1,-1].flatten()\n",
    "        truess = trues[:,:,-1,-1].flatten()\n",
    "\n",
    "        start_date = '2023-01-01 00:00'\n",
    "        end_date = '2023-12-31 23:00'\n",
    "        \n",
    "        if save_data:\n",
    "            start_date = '2020-01-11 13:00:00' \n",
    "            end_date = '2024-05-28 03:00:00'\n",
    "        \n",
    "        time_index = pandas.date_range(start=start_date, end=end_date, freq='H')\n",
    "\n",
    "        # Adjust the time index to match the length of the data\n",
    "        min_len = min(len(time_index), len(predss))\n",
    "        time_index = time_index[:min_len]\n",
    "        #truess = np.roll(truess, pred_len)\n",
    "        \n",
    "        predss = predss[:min_len]\n",
    "        truess = truess[:min_len]\n",
    "\n",
    "        mae, mse, rmse, mape, mspe, rse, corr, wape, nse, pfe, tpe, rfactor, pfactor95 = metric(preds, trues)\n",
    "        \n",
    "        if save_data:\n",
    "            self.saveData(truess, predss, start_date, end_date, pred_len)\n",
    "\n",
    "        \n",
    "        else:\n",
    "            #gtt = np.concatenate((time_index, truess), axis = 0)\n",
    "            #pdt = np.concatenate((time_index, predss), axis = 0)\n",
    "            \n",
    "            #visual(gtt, pdt, 'some_file.pdf')\n",
    "            \n",
    "            # Plotting\n",
    "            # Set the font to Times New Roman\n",
    "            plt.rcParams['font.family'] = 'serif'\n",
    "            plt.rcParams['font.size'] = 14  # Increase base font size\n",
    "            plt.rcParams['font.weight'] = 'normal'\n",
    "    \n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            \n",
    "            ax.plot(time_index, predss, label='PatchTST Predictions', color='blue')\n",
    "            ax.plot(time_index, truess, label='Observed height', color='#BB0000')\n",
    "            ax.plot([], [], ' ', label=f\"NSE: {round(nse,4)}\")\n",
    "            ax.plot([], [], ' ', label=f\"WAPE: {round(wape,2)}\")\n",
    "            \n",
    "            ax.set_xlabel('Time', fontsize=16)\n",
    "            ax.set_ylabel('River Level', fontsize=16)\n",
    "            \n",
    "            ax.set_ylim(0, 2)\n",
    "            ax.legend(loc='upper left', fontsize=16)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "            \n",
    "            axins1 = inset_axes(ax, width=\"60%\", height=\"40%\", loc='upper right')\n",
    "            axins1.plot(time_index, predss, color='blue')\n",
    "            axins1.plot(time_index, truess, color='#BB0000')\n",
    "            axins1.set_xlabel('Time', fontsize=14)\n",
    "            axins1.set_ylabel('River Level', fontsize=14)\n",
    "            \n",
    "            axins1.xaxis.set_major_locator(mdates.DayLocator(interval=5))\n",
    "            axins1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "    \n",
    "            #may have to change it\n",
    "            axins1.set_ylim(0,1)\n",
    "            start_date = pandas.Timestamp('2023-05-01 07:00')  # Adjust date to match your dataset\n",
    "            end_date = pandas.Timestamp('2023-06-02 06:00')  # Adjust date to match your dataset\n",
    "            axins1.set_xlim(start_date, end_date)\n",
    "        \n",
    "            \n",
    "            # Apply mark_inset to show the bounds of the inset on the main plot\n",
    "            mark_inset(ax, axins1, loc1=3, loc2=4, fc=\"none\", ec=\"0.25\")  # Try adjusting loc1 and loc2 here        \n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Save the figure\n",
    "    \n",
    "            plt.savefig('PatchTSTfig2.png', dpi=300)  # Update the path as needed\n",
    "            plt.close(fig)\n",
    "    \n",
    "        print('mse:{}, mae:{}, rse:{}, rmse:{}, wape:{}, nse:{}, pfe:{}, tpe:{}, rfactor:{}, pfactor95:{}'.format(mse, mae, rse, rmse, wape, nse, pfe, tpe, rfactor, pfactor95))\n",
    "        f = open(\"result.txt\", 'a')\n",
    "        f.write(setting + \"  \\n\")\n",
    "        f.write('mse:{}, mae:{}, rse:{}, rmse:{}, wape:{}, nse:{}, pfe:{}, tpe:{}, rfactor:{}, pfactor95:{}'.format(mse, mae, rse, rmse, wape, nse, pfe, tpe, rfactor, pfactor95))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "\n",
    "        # np.save(folder_path + 'metrics.npy', np.array([mae, mse, rmse, mape, mspe,rse, corr]))\n",
    "        np.save(folder_path + 'pred.npy', preds)\n",
    "        # np.save(folder_path + 'true.npy', trues)\n",
    "        # np.save(folder_path + 'x.npy', inputx)\n",
    "        return\n",
    "\n",
    "    def predict(self, setting, load=False):\n",
    "        pred_data, pred_loader = self._get_data(flag='pred')\n",
    "\n",
    "        if load:\n",
    "            path = os.path.join(self.args.checkpoints, setting)\n",
    "            best_model_path = path + '/' + 'checkpoint.pth'\n",
    "            self.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        preds = []\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(pred_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float()\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[2]]).float().to(batch_y.device)\n",
    "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                            outputs = self.model(batch_x)\n",
    "                        else:\n",
    "                            if self.args.output_attention:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                            else:\n",
    "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
    "                        outputs = self.model(batch_x)\n",
    "                    else:\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                pred = outputs.detach().cpu().numpy()  # .squeeze()\n",
    "                preds.append(pred)\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "\n",
    "        # result save\n",
    "        folder_path = './results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        np.save(folder_path + 'real_prediction.npy', preds)\n",
    "\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "367b6acc-eb59-49b6-8e82-9147523e013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "krishna = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a1622-86c2-4202-8dd6-1a0d8bad73b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1e9b090-c4c7-4d2a-a363-e38654f6e7cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Configuration:\n",
      "Model ID: gaze_height_full\n",
      "Model: PatchTST\n",
      "Dataset: gaze_height_full\n",
      "Use GPU: cuda:0\n",
      ">>>>>>> Testing : 13_1_PatchTST_gaze_height_full_ftM_sl13_ll0_pl1_dm16_nh8_el16_dl1_df512_fc1_ebfixed_dtTrue_Exp_0 <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "get data\n",
      "woring..............\n",
      "working.................\n",
      "2023-04-26 09:00:00 2024-05-28 03:00:00\n",
      "test 9418\n",
      "gotten data\n",
      "loading model\n",
      "parameter_count_test:  289345\n",
      "(512, 1, 5)\n",
      "(512, 1, 5)\n",
      "(512, 1, 5)\n",
      "(512, 1, 5)\n",
      "(512, 1, 5)\n",
      "(512, 1, 5)\n",
      "(512, 1, 5)\n",
      "(512, 1, 5)\n",
      "(512, 1, 5)\n",
      "(512, 1, 5)\n",
      "(512, 1, 5)\n",
      "(512, 1, 5)\n",
      "(512, 1, 5)\n",
      "(512, 1, 5)\n",
      "(512, 1, 5)\n",
      "(512, 1, 5)\n",
      "(512, 1, 5)\n",
      "(512, 1, 5)\n",
      "9216 9216\n",
      "mse:0.0002809483848977834, mae:0.009862545877695084, rse:0.05633654072880745, rmse:0.01676151528954506, wape:2.481062090353372, nse:0.9968261942267418, pfe:0.0050705671310424805, tpe:74820, rfactor:0.05633654072880745, pfactor95:2432.0\n"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.random_seed = 2021\n",
    "        self.is_training = 0\n",
    "        self.model_id = 'gaze_height_full'\n",
    "        self.model = 'PatchTST'\n",
    "        self.data = 'gaze_height_full'\n",
    "        self.root_path = './dataset/'\n",
    "        self.data_path = 'chattahoochee_1hr_02336490.csv'\n",
    "        self.features = 'M'\n",
    "        self.target = 'gaze_height'\n",
    "        self.freq = 'h'\n",
    "        self.checkpoints = './checkpoints/'\n",
    "        self.seq_len = 13\n",
    "        self.label_len = 0\n",
    "        self.pred_len = 1 #should be set using loop\n",
    "        self.enc_in = 7\n",
    "        self.e_layers = 16\n",
    "        self.n_heads = 8\n",
    "        self.d_model = 16\n",
    "        self.d_ff = 512\n",
    "        self.dropout = 0.3\n",
    "        self.fc_dropout = 0.3\n",
    "        self.head_dropout = 0\n",
    "        self.patch_len = 16\n",
    "        self.stride = 8\n",
    "        self.des = 'Exp'\n",
    "        self.train_epochs = 30\n",
    "        self.embed = 'fixed'\n",
    "        self.itr = 1 \n",
    "        self.batch_size = 512 \n",
    "        self.learning_rate = 0.002\n",
    "        #fc_dropout = 0.05\n",
    "        #head_dropout = 0.0\n",
    "        #patch_len = 16\n",
    "        #stride = 8\n",
    "        self.padding_patch = 'end'\n",
    "        self.revin = True\n",
    "        self.affine = False\n",
    "        self.subtract_last = 0\n",
    "        self.decomposition = 0\n",
    "        self.kernel_size = 25\n",
    "        self.individual = 0\n",
    "        self.embed_type = 0\n",
    "        #enc_in = 7\n",
    "        #e_layers = 2\n",
    "        self.dec_in = 7\n",
    "        self.c_out = 7\n",
    "        #d_model = 512\n",
    "        #n_heads = 8\n",
    "        self.d_layers = 1\n",
    "        #d_ff = 2048\n",
    "        self.moving_avg = 25\n",
    "        self.factor = 1\n",
    "        self.distil = True\n",
    "        self.dropout = 0.05\n",
    "        self.embed = 'fixed'\n",
    "        self.activation = 'gelu'\n",
    "        self.output_attention = False\n",
    "        self.do_predict = False\n",
    "        self.num_workers = 10\n",
    "        #itr = 2\n",
    "        #train_epochs = 100\n",
    "        #batch_size = 128\n",
    "        self.patience = 6\n",
    "        #learning_rate = 0.0001\n",
    "        #des = 'test'\n",
    "        self.loss = 'mse'\n",
    "        self.lradj = 'type3'\n",
    "        self.pct_start = 0.3\n",
    "        self.use_amp = False\n",
    "        self.use_gpu = torch.cuda.is_available()\n",
    "        self.gpu = 0\n",
    "        self.use_multi_gpu = False\n",
    "        self.devices = '0,1,2,3'\n",
    "        self.test_flop = False\n",
    "        self.tempfeat = -3\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(args.random_seed)\n",
    "torch.manual_seed(args.random_seed)\n",
    "np.random.seed(args.random_seed)\n",
    "\n",
    "# GPU configuration\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    device_ids = [int(id_) for id_ in args.devices.split(',')]\n",
    "    gpu = device_ids[0]\n",
    "\n",
    "# Print out the experiment settings\n",
    "print('Experiment Configuration:')\n",
    "print('Model ID:', args.model_id)\n",
    "print('Model:', args.model)\n",
    "print('Dataset:', args.data)\n",
    "\n",
    "# Example Experiment Code\n",
    "Exp = Exp_Main  # Assuming Exp_Main is defined elsewhere\n",
    "\n",
    "if args.is_training:\n",
    "    for ii in range(args.itr):\n",
    "        setting = f'{args.model_id}_{args.model}_{args.data}_ft{args.features}_sl{args.seq_len}_ll{args.label_len}_pl{args.pred_len}_dm{args.d_model}_nh{args.n_heads}_el{args.e_layers}_dl{args.d_layers}_df{args.d_ff}_fc{args.factor}_eb{args.embed}_dt{args.distil}_{args.des}_{ii}'\n",
    "        exp = Exp(args)  # Assuming Exp is instantiated with all required settings\n",
    "        print(f'>>>>>>> Start training : {setting} >>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "        trained_model = exp.train(setting)\n",
    "        print(f'>>>>>>> Testing : {setting} <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "        exp.test(setting)\n",
    "\n",
    "        if args.do_predict:\n",
    "            print(f'>>>>>>> Predicting : {setting} <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "            exp.predict(setting, True)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "else:\n",
    "    ii = 0\n",
    "    setting = f'{args.seq_len}_{args.pred_len}_{args.model}_{args.data}_ft{args.features}_sl{args.seq_len}_ll{args.label_len}_pl{args.pred_len}_dm{args.d_model}_nh{args.n_heads}_el{args.e_layers}_dl{args.d_layers}_df{args.d_ff}_fc{args.factor}_eb{args.embed}_dt{args.distil}_{args.des}_{ii}'\n",
    "    exp = Exp(args)  # set experiments\n",
    "    print(f'>>>>>>> Testing : {setting} <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "    exp.test(setting, test=1)\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a37cb61d-9519-499e-a8d7-c0bd5294126a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get data\n",
      "woring..............\n",
      "working.................\n",
      "2023-04-26 09:00:00 2024-05-28 03:00:00\n",
      "test 9418\n",
      "gotten data\n",
      "get data\n",
      "woring..............\n",
      "working.................\n",
      "2010-01-01 00:00:00 2022-12-17 00:00:00\n",
      "train 113003\n",
      "gotten data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_data, test_loader = exp._get_data(flag='test')\n",
    "\n",
    "train_data, train_loader = exp._get_data(flag='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "491e2a29-791d-43b6-84a2-7b198143e5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__read_data__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_is_protocol',\n",
       " 'data_path',\n",
       " 'data_stamp',\n",
       " 'data_x',\n",
       " 'data_y',\n",
       " 'features',\n",
       " 'freq',\n",
       " 'inverse_transform',\n",
       " 'label_len',\n",
       " 'pred_len',\n",
       " 'root_path',\n",
       " 'scale',\n",
       " 'scaler',\n",
       " 'seq_len',\n",
       " 'set_type',\n",
       " 'target',\n",
       " 'timeenc']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(test_data)\n",
    "#dir(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c253ffb-c0cb-4e4c-b0a3-e52339a9ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "someval1 = next(iter(train_loader))\n",
    "someval2 = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0db6871-7b10-4ead-bdd9-09b93c4474c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "background = someval1[0].float().to(device)\n",
    "tests = someval2[0].float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69867c22-a1d2-424e-bbe0-c9fb9f496322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4120,  0.0218, -0.1749,  0.0952],\n",
       "         [-0.4120,  0.0218, -0.1749, -0.0277],\n",
       "         [-0.4120, -0.0440, -0.1749, -0.1041],\n",
       "         [-0.3507,  0.0218, -0.1749, -0.1506],\n",
       "         [-0.4120, -0.3729, -0.1749, -0.1772],\n",
       "         [-0.4120, -0.4387, -0.1749, -0.2038]],\n",
       "\n",
       "        [[-0.4120,  0.0218, -0.1749, -0.0277],\n",
       "         [-0.4120, -0.0440, -0.1749, -0.1041],\n",
       "         [-0.3507,  0.0218, -0.1749, -0.1506],\n",
       "         [-0.4120, -0.3729, -0.1749, -0.1772],\n",
       "         [-0.4120, -0.4387, -0.1749, -0.2038],\n",
       "         [-0.4120, -0.3729, -0.1749, -0.2270]],\n",
       "\n",
       "        [[-0.4120, -0.0440, -0.1749, -0.1041],\n",
       "         [-0.3507,  0.0218, -0.1749, -0.1506],\n",
       "         [-0.4120, -0.3729, -0.1749, -0.1772],\n",
       "         [-0.4120, -0.4387, -0.1749, -0.2038],\n",
       "         [-0.4120, -0.3729, -0.1749, -0.2270],\n",
       "         [-0.4120, -0.4387, -0.1749, -0.2470]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.2013, -1.2941,  0.6544, -0.3965],\n",
       "         [ 0.2627, -1.2283,  0.6544, -0.4928],\n",
       "         [ 0.2627, -1.1625,  0.6544, -0.5526],\n",
       "         [ 0.3240, -1.0309,  0.5853, -0.4795],\n",
       "         [ 0.3240, -0.8335,  0.5853, -0.1706],\n",
       "         [ 0.3240, -0.7019,  0.5853,  0.0886]],\n",
       "\n",
       "        [[ 0.2627, -1.2283,  0.6544, -0.4928],\n",
       "         [ 0.2627, -1.1625,  0.6544, -0.5526],\n",
       "         [ 0.3240, -1.0309,  0.5853, -0.4795],\n",
       "         [ 0.3240, -0.8335,  0.5853, -0.1706],\n",
       "         [ 0.3240, -0.7019,  0.5853,  0.0886],\n",
       "         [ 0.3240, -0.5703,  0.7235,  0.2514]],\n",
       "\n",
       "        [[ 0.2627, -1.1625,  0.6544, -0.5526],\n",
       "         [ 0.3240, -1.0309,  0.5853, -0.4795],\n",
       "         [ 0.3240, -0.8335,  0.5853, -0.1706],\n",
       "         [ 0.3240, -0.7019,  0.5853,  0.0886],\n",
       "         [ 0.3240, -0.5703,  0.7235,  0.2514],\n",
       "         [ 0.2013, -0.4387,  0.5853,  0.5205]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "someval2[1].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9ce029c-e24a-44ec-8482-93f7cfe4b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1 = someval2[0][:5,:,:].float().to(device)\n",
    "out1 = exp.model(ss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a763758-d475-41d5-b1ce-61b10b7a8632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4120,  0.0218, -0.1749,  0.0952],\n",
       "         [-0.4120,  0.0218, -0.1749, -0.0277],\n",
       "         [-0.4120, -0.0440, -0.1749, -0.1041],\n",
       "         [-0.3507,  0.0218, -0.1749, -0.1506],\n",
       "         [-0.4120, -0.3729, -0.1749, -0.1772],\n",
       "         [-0.4120, -0.4387, -0.1749, -0.2038]],\n",
       "\n",
       "        [[-0.4120,  0.0218, -0.1749, -0.0277],\n",
       "         [-0.4120, -0.0440, -0.1749, -0.1041],\n",
       "         [-0.3507,  0.0218, -0.1749, -0.1506],\n",
       "         [-0.4120, -0.3729, -0.1749, -0.1772],\n",
       "         [-0.4120, -0.4387, -0.1749, -0.2038],\n",
       "         [-0.4120, -0.3729, -0.1749, -0.2270]],\n",
       "\n",
       "        [[-0.4120, -0.0440, -0.1749, -0.1041],\n",
       "         [-0.3507,  0.0218, -0.1749, -0.1506],\n",
       "         [-0.4120, -0.3729, -0.1749, -0.1772],\n",
       "         [-0.4120, -0.4387, -0.1749, -0.2038],\n",
       "         [-0.4120, -0.3729, -0.1749, -0.2270],\n",
       "         [-0.4120, -0.4387, -0.1749, -0.2470]],\n",
       "\n",
       "        [[-0.3507,  0.0218, -0.1749, -0.1506],\n",
       "         [-0.4120, -0.3729, -0.1749, -0.1772],\n",
       "         [-0.4120, -0.4387, -0.1749, -0.2038],\n",
       "         [-0.4120, -0.3729, -0.1749, -0.2270],\n",
       "         [-0.4120, -0.4387, -0.1749, -0.2470],\n",
       "         [-0.4120, -0.3729, -0.1058, -0.2569]],\n",
       "\n",
       "        [[-0.4120, -0.3729, -0.1749, -0.1772],\n",
       "         [-0.4120, -0.4387, -0.1749, -0.2038],\n",
       "         [-0.4120, -0.3729, -0.1749, -0.2270],\n",
       "         [-0.4120, -0.4387, -0.1749, -0.2470],\n",
       "         [-0.4120, -0.3729, -0.1058, -0.2569],\n",
       "         [-0.4120, -0.4387, -0.1058, -0.2403]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "someval2[1][:5,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe59b758-f5d4-494b-ac9f-69d7b0279ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4007,  0.1089, -0.1788,  0.2372],\n",
       "         [-0.4042,  0.1331, -0.1856,  0.1686],\n",
       "         [-0.4126,  0.1409, -0.1951,  0.1468],\n",
       "         [-0.4267,  0.1347, -0.2096,  0.1169],\n",
       "         [-0.4495,  0.1300, -0.2234,  0.1247],\n",
       "         [-0.4766,  0.1213, -0.2308,  0.1102]],\n",
       "\n",
       "        [[-0.4148,  0.0238, -0.1861,  0.0812],\n",
       "         [-0.4189,  0.0158, -0.1958, -0.0048],\n",
       "         [-0.4354, -0.0082, -0.2156, -0.0261],\n",
       "         [-0.4536, -0.0234, -0.2262, -0.0785],\n",
       "         [-0.4820, -0.0291, -0.2364, -0.0816],\n",
       "         [-0.5046, -0.0343, -0.2300, -0.0931]],\n",
       "\n",
       "        [[-0.4115, -0.0038, -0.1768, -0.0035],\n",
       "         [-0.4196, -0.0197, -0.1833, -0.0793],\n",
       "         [-0.4433, -0.0409, -0.1996, -0.1009],\n",
       "         [-0.4652, -0.0509, -0.2129, -0.1516],\n",
       "         [-0.4833, -0.0492, -0.2207, -0.1584],\n",
       "         [-0.4960, -0.0416, -0.2241, -0.1635]],\n",
       "\n",
       "        [[-0.4251, -0.0630, -0.1795, -0.0767],\n",
       "         [-0.4523, -0.1046, -0.1922, -0.1330],\n",
       "         [-0.4913, -0.1346, -0.2015, -0.1568],\n",
       "         [-0.5190, -0.1500, -0.2087, -0.2024],\n",
       "         [-0.5294, -0.1457, -0.2096, -0.2004],\n",
       "         [-0.5230, -0.1262, -0.2021, -0.1950]],\n",
       "\n",
       "        [[-0.3324,  0.0512, -0.1773, -0.1312],\n",
       "         [-0.3405,  0.0568, -0.1852, -0.1710],\n",
       "         [-0.3625,  0.0702, -0.1896, -0.1975],\n",
       "         [-0.3762,  0.0880, -0.1916, -0.2353],\n",
       "         [-0.3767,  0.1089, -0.1900, -0.2215],\n",
       "         [-0.3670,  0.1333, -0.1793, -0.2020]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e2fe9d8-10e6-49f9-ba75-5124e81a583e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "761f6c6a-54cd-444b-af86-812095cfb1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 6, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "someval1[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d0d8652-fa83-4022-a2a8-2157cc83bbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 24, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "someval1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fd34541-4bac-48c8-b4d6-05b52f641c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0173,  0.0218, -0.1749,  0.8760],\n",
       "         [-0.0440,  0.0218, -0.2441,  0.9025],\n",
       "         [-0.1054,  0.0218, -0.2441,  0.9225],\n",
       "         [-0.1054,  0.0876, -0.2441,  0.9258],\n",
       "         [-0.1667, -0.0440, -0.3132,  0.9125],\n",
       "         [-0.1667,  0.0218, -0.3132,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.3132,  0.8394],\n",
       "         [-0.3507,  0.0218, -0.3132,  0.7896],\n",
       "         [-0.4120,  0.0218, -0.3132,  0.7597],\n",
       "         [-0.3507,  0.1534, -0.3132,  0.7530],\n",
       "         [-0.3507,  0.1534, -0.2441,  0.7796],\n",
       "         [-0.2894,  0.1534, -0.2441,  0.8294],\n",
       "         [-0.2280,  0.2192, -0.1058,  0.8992],\n",
       "         [-0.2894,  0.2192, -0.1749,  0.9557],\n",
       "         [-0.1667,  0.2192, -0.0367,  0.9956],\n",
       "         [-0.2894,  0.1534, -0.1058,  1.0188],\n",
       "         [-0.3507,  0.1534, -0.1749,  1.0122],\n",
       "         [-0.3507,  0.0876, -0.1058,  0.9956],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.9524],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8162],\n",
       "         [-0.4120, -0.1098, -0.1749,  0.7032],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.5005],\n",
       "         [-0.4120,  0.0876, -0.1749,  0.2746]],\n",
       "\n",
       "        [[-0.0440,  0.0218, -0.2441,  0.9025],\n",
       "         [-0.1054,  0.0218, -0.2441,  0.9225],\n",
       "         [-0.1054,  0.0876, -0.2441,  0.9258],\n",
       "         [-0.1667, -0.0440, -0.3132,  0.9125],\n",
       "         [-0.1667,  0.0218, -0.3132,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.3132,  0.8394],\n",
       "         [-0.3507,  0.0218, -0.3132,  0.7896],\n",
       "         [-0.4120,  0.0218, -0.3132,  0.7597],\n",
       "         [-0.3507,  0.1534, -0.3132,  0.7530],\n",
       "         [-0.3507,  0.1534, -0.2441,  0.7796],\n",
       "         [-0.2894,  0.1534, -0.2441,  0.8294],\n",
       "         [-0.2280,  0.2192, -0.1058,  0.8992],\n",
       "         [-0.2894,  0.2192, -0.1749,  0.9557],\n",
       "         [-0.1667,  0.2192, -0.0367,  0.9956],\n",
       "         [-0.2894,  0.1534, -0.1058,  1.0188],\n",
       "         [-0.3507,  0.1534, -0.1749,  1.0122],\n",
       "         [-0.3507,  0.0876, -0.1058,  0.9956],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.9524],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8162],\n",
       "         [-0.4120, -0.1098, -0.1749,  0.7032],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.5005],\n",
       "         [-0.4120,  0.0876, -0.1749,  0.2746],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.0952]],\n",
       "\n",
       "        [[-0.1054,  0.0218, -0.2441,  0.9225],\n",
       "         [-0.1054,  0.0876, -0.2441,  0.9258],\n",
       "         [-0.1667, -0.0440, -0.3132,  0.9125],\n",
       "         [-0.1667,  0.0218, -0.3132,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.3132,  0.8394],\n",
       "         [-0.3507,  0.0218, -0.3132,  0.7896],\n",
       "         [-0.4120,  0.0218, -0.3132,  0.7597],\n",
       "         [-0.3507,  0.1534, -0.3132,  0.7530],\n",
       "         [-0.3507,  0.1534, -0.2441,  0.7796],\n",
       "         [-0.2894,  0.1534, -0.2441,  0.8294],\n",
       "         [-0.2280,  0.2192, -0.1058,  0.8992],\n",
       "         [-0.2894,  0.2192, -0.1749,  0.9557],\n",
       "         [-0.1667,  0.2192, -0.0367,  0.9956],\n",
       "         [-0.2894,  0.1534, -0.1058,  1.0188],\n",
       "         [-0.3507,  0.1534, -0.1749,  1.0122],\n",
       "         [-0.3507,  0.0876, -0.1058,  0.9956],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.9524],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8162],\n",
       "         [-0.4120, -0.1098, -0.1749,  0.7032],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.5005],\n",
       "         [-0.4120,  0.0876, -0.1749,  0.2746],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.0952],\n",
       "         [-0.4120,  0.0218, -0.1749, -0.0277]],\n",
       "\n",
       "        [[-0.1054,  0.0876, -0.2441,  0.9258],\n",
       "         [-0.1667, -0.0440, -0.3132,  0.9125],\n",
       "         [-0.1667,  0.0218, -0.3132,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.3132,  0.8394],\n",
       "         [-0.3507,  0.0218, -0.3132,  0.7896],\n",
       "         [-0.4120,  0.0218, -0.3132,  0.7597],\n",
       "         [-0.3507,  0.1534, -0.3132,  0.7530],\n",
       "         [-0.3507,  0.1534, -0.2441,  0.7796],\n",
       "         [-0.2894,  0.1534, -0.2441,  0.8294],\n",
       "         [-0.2280,  0.2192, -0.1058,  0.8992],\n",
       "         [-0.2894,  0.2192, -0.1749,  0.9557],\n",
       "         [-0.1667,  0.2192, -0.0367,  0.9956],\n",
       "         [-0.2894,  0.1534, -0.1058,  1.0188],\n",
       "         [-0.3507,  0.1534, -0.1749,  1.0122],\n",
       "         [-0.3507,  0.0876, -0.1058,  0.9956],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.9524],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8162],\n",
       "         [-0.4120, -0.1098, -0.1749,  0.7032],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.5005],\n",
       "         [-0.4120,  0.0876, -0.1749,  0.2746],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.0952],\n",
       "         [-0.4120,  0.0218, -0.1749, -0.0277],\n",
       "         [-0.4120, -0.0440, -0.1749, -0.1041]],\n",
       "\n",
       "        [[-0.1667, -0.0440, -0.3132,  0.9125],\n",
       "         [-0.1667,  0.0218, -0.3132,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.3132,  0.8394],\n",
       "         [-0.3507,  0.0218, -0.3132,  0.7896],\n",
       "         [-0.4120,  0.0218, -0.3132,  0.7597],\n",
       "         [-0.3507,  0.1534, -0.3132,  0.7530],\n",
       "         [-0.3507,  0.1534, -0.2441,  0.7796],\n",
       "         [-0.2894,  0.1534, -0.2441,  0.8294],\n",
       "         [-0.2280,  0.2192, -0.1058,  0.8992],\n",
       "         [-0.2894,  0.2192, -0.1749,  0.9557],\n",
       "         [-0.1667,  0.2192, -0.0367,  0.9956],\n",
       "         [-0.2894,  0.1534, -0.1058,  1.0188],\n",
       "         [-0.3507,  0.1534, -0.1749,  1.0122],\n",
       "         [-0.3507,  0.0876, -0.1058,  0.9956],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.9524],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8859],\n",
       "         [-0.3507, -0.0440, -0.1749,  0.8162],\n",
       "         [-0.4120, -0.1098, -0.1749,  0.7032],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.5005],\n",
       "         [-0.4120,  0.0876, -0.1749,  0.2746],\n",
       "         [-0.4120,  0.0218, -0.1749,  0.0952],\n",
       "         [-0.4120,  0.0218, -0.1749, -0.0277],\n",
       "         [-0.4120, -0.0440, -0.1749, -0.1041],\n",
       "         [-0.3507,  0.0218, -0.1749, -0.1506]]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests[:5,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fabbce65-d3ba-44c9-b8d6-df02db005ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = exp.model(background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21029b4b-d80e-4bb9-8ce9-fb8ac8e45110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 6, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "926b452b-e03c-4662-9d56-8bc3827b72ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 24, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "594c0769-7e21-45b3-9590-485f8b63e3e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m test_np \u001b[38;5;241m=\u001b[39m tests\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Create a masker that uses the background data for replacing \"masked\" features\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m masker \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241m.\u001b[39mmaskers\u001b[38;5;241m.\u001b[39mIndependent(data\u001b[38;5;241m=\u001b[39mbackground_np)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#masker = shap.maskers.Tabular(background_np, hclustering='correlation')\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Create the SHAP explainer using the model function and the masker\u001b[39;00m\n\u001b[1;32m     22\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mExplainer(f, background_np)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shap' is not defined"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    x = torch.from_numpy().to(device)\n",
    "    out = exp.model(x)\n",
    "    return out[:, 5, 2].numpy()\n",
    "\n",
    "\n",
    "def time_series_masker(data, mask):\n",
    "    # Replace masked elements with the mean of the series (simplified approach)\n",
    "    masked_data = data.copy()\n",
    "    masked_data[mask] = np.mean(data, axis=0)\n",
    "    return masked_data\n",
    "\n",
    "# Convert background to a NumPy array if it's not already\n",
    "background_np = background.cpu().detach().numpy()\n",
    "test_np = tests.cpu().detach().numpy()\n",
    "# Create a masker that uses the background data for replacing \"masked\" features\n",
    "masker = shap.maskers.Independent(data=background_np)\n",
    "#masker = shap.maskers.Tabular(background_np, hclustering='correlation')\n",
    "\n",
    "\n",
    "# Create the SHAP explainer using the model function and the masker\n",
    "explainer = shap.Explainer(f, background_np)\n",
    "shap_values = explainer(test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ad5a56-5b49-43ad-90ce-e63be120f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa3d1f8-3fd8-4670-87eb-35f958622b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8764b-9c94-4e31-b956-c3759217e2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c77f5-cade-485f-8b64-29ca22ff8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2023-01-01 00:00'\n",
    "end_date = '2023-12-31 23:00'\n",
    "        \n",
    "time_index = pd.date_range(start=start_date, end=end_date, freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb59532-5574-4672-8a40-c9ecddd2dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResults(predss, truess, model_name, start_date='2023-01-01 00:00', end_date = '2023-12-31 23:00'):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.dates as mdates\n",
    "    from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
    "\n",
    "    time_index = pandas.date_range(start=start_date, end=end_date, freq='H')\n",
    "\n",
    "    # Adjust the time index to match the length of the data\n",
    "    min_len = min(len(time_index), len(predss))\n",
    "    time_index = time_index[:min_len]\n",
    "    truess = np.roll(truess, 6)\n",
    "    \n",
    "    predss = predss[:min_len]\n",
    "    truess = truess[:min_len]\n",
    "\n",
    "    \n",
    "    #gtt = np.concatenate((time_index, truess), axis = 0)\n",
    "    #pdt = np.concatenate((time_index, predss), axis = 0)\n",
    "    \n",
    "    #visual(gtt, pdt, 'some_file.pdf')\n",
    "    \n",
    "    # Plotting\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    plt.title('{0} Model Predictions with a 6-Hour Forecast Horizon for year 2023'.format(model_name))\n",
    "    \n",
    "    ax.plot(time_index, predss, label='{0} Predictions'.format(model_name), color='blue')\n",
    "    ax.plot(time_index, truess, label='Actual height', color='#BB0000')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Gaze height')\n",
    "    \n",
    "    ax.set_ylim(-1, 10)\n",
    "    ax.legend(loc='upper left')\n",
    "    \n",
    "    axins1 = inset_axes(ax, width=\"60%\", height=\"40%\", loc='upper right')\n",
    "    axins1.plot(time_index, predss, color='blue')\n",
    "    axins1.plot(time_index, truess, color='#BB0000')\n",
    "    axins1.set_xlabel('time')\n",
    "    axins1.set_ylabel('Gaze Height')\n",
    "\n",
    "    axins1.xaxis.set_major_locator(mdates.DayLocator(interval=5))\n",
    "    axins1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "\n",
    "    #may have to change it\n",
    "    axins1.set_ylim(-1,6)\n",
    "    start_date = pandas.Timestamp('2023-05-01')  # Adjust date to match the dataset\n",
    "    end_date = pandas.Timestamp('2023-06-01')  # Adjust date to match the dataset\n",
    "    axins1.set_xlim(start_date, end_date)\n",
    "\n",
    "    \n",
    "    # Apply mark_inset to show the bounds of the inset on the main plot\n",
    "    mark_inset(ax, axins1, loc1=3, loc2=4, fc=\"none\", ec=\"0.25\")      \n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    \n",
    "    plt.savefig('Results.png') \n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3011204-64e3-4df8-a905-305822c8e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotResults(out1.detach().cpu().numpy(), ss1.detach().cpu().numpy(), 'PatchTST', start_date='2023-01-01 00:00', end_date = '2023-12-31 23:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3fda69-4cab-42c5-a749-d805580fb7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e06982-f72f-4de0-998d-5e106ec5cd5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
